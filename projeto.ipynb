{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The path does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m mp_face_mesh\u001b[39m.\u001b[39;49mFaceMesh(min_detection_confidence\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m, min_tracking_confidence\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m) \u001b[39mas\u001b[39;00m facemesh:\n\u001b[0;32m      4\u001b[0m     \u001b[39mwhile\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m      5\u001b[0m         sucesso, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\lucas\\Documents\\Programação\\Iniciação Cientifica\\TrackingPython\\venv\\lib\\site-packages\\mediapipe\\python\\solutions\\face_mesh.py:94\u001b[0m, in \u001b[0;36mFaceMesh.__init__\u001b[1;34m(self, static_image_mode, max_num_faces, refine_landmarks, min_detection_confidence, min_tracking_confidence)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m     70\u001b[0m              static_image_mode\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m              max_num_faces\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     72\u001b[0m              refine_landmarks\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m              min_detection_confidence\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[0;32m     74\u001b[0m              min_tracking_confidence\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m):\n\u001b[0;32m     75\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Initializes a MediaPipe Face Mesh object.\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \n\u001b[0;32m     77\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m      https://solutions.mediapipe.dev/face_mesh#min_tracking_confidence.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m   \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m     95\u001b[0m       binary_graph_path\u001b[39m=\u001b[39;49m_BINARYPB_FILE_PATH,\n\u001b[0;32m     96\u001b[0m       side_inputs\u001b[39m=\u001b[39;49m{\n\u001b[0;32m     97\u001b[0m           \u001b[39m'\u001b[39;49m\u001b[39mnum_faces\u001b[39;49m\u001b[39m'\u001b[39;49m: max_num_faces,\n\u001b[0;32m     98\u001b[0m           \u001b[39m'\u001b[39;49m\u001b[39mwith_attention\u001b[39;49m\u001b[39m'\u001b[39;49m: refine_landmarks,\n\u001b[0;32m     99\u001b[0m           \u001b[39m'\u001b[39;49m\u001b[39muse_prev_landmarks\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mnot\u001b[39;49;00m static_image_mode,\n\u001b[0;32m    100\u001b[0m       },\n\u001b[0;32m    101\u001b[0m       calculator_params\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    102\u001b[0m           \u001b[39m'\u001b[39;49m\u001b[39mfacedetectionshortrangecpu__facedetectionshortrange__facedetection__TensorsToDetectionsCalculator.min_score_thresh\u001b[39;49m\u001b[39m'\u001b[39;49m:\n\u001b[0;32m    103\u001b[0m               min_detection_confidence,\n\u001b[0;32m    104\u001b[0m           \u001b[39m'\u001b[39;49m\u001b[39mfacelandmarkcpu__ThresholdingCalculator.threshold\u001b[39;49m\u001b[39m'\u001b[39;49m:\n\u001b[0;32m    105\u001b[0m               min_tracking_confidence,\n\u001b[0;32m    106\u001b[0m       },\n\u001b[0;32m    107\u001b[0m       outputs\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mmulti_face_landmarks\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\lucas\\Documents\\Programação\\Iniciação Cientifica\\TrackingPython\\venv\\lib\\site-packages\\mediapipe\\python\\solution_base.py:265\u001b[0m, in \u001b[0;36mSolutionBase.__init__\u001b[1;34m(self, binary_graph_path, graph_config, calculator_params, graph_options, side_inputs, outputs, stream_type_hints)\u001b[0m\n\u001b[0;32m    263\u001b[0m validated_graph \u001b[39m=\u001b[39m validated_graph_config\u001b[39m.\u001b[39mValidatedGraphConfig()\n\u001b[0;32m    264\u001b[0m \u001b[39mif\u001b[39;00m binary_graph_path:\n\u001b[1;32m--> 265\u001b[0m   validated_graph\u001b[39m.\u001b[39;49minitialize(\n\u001b[0;32m    266\u001b[0m       binary_graph_path\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root_path, binary_graph_path))\n\u001b[0;32m    267\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m   validated_graph\u001b[39m.\u001b[39minitialize(graph_config\u001b[39m=\u001b[39mgraph_config)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The path does not exist."
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh() as facemesh:\n",
    "    while cap.isOpened():\n",
    "        sucesso, frame = cap.read()\n",
    "        if not sucesso:\n",
    "            print('Ignorando o frame vazio da camera.')\n",
    "            continue\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        saida_facemesh = facemesh.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            for face_landmarks in saida_facemesh.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,cv2.imshow('Camera',frame))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.imshow('Camera',frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
